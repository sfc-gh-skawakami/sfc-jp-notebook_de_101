{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb54bdb",
   "metadata": {},
   "source": [
    "## Avalanche (架空のウィンタースポーツ用品会社)\n",
    "\n",
    "Avalancheの注文履歴・出荷データを, [Snowflake 上で動作する pandas](https://docs.snowflake.com/en/developer-guide/snowpark/python/pandas-on-snowflake) を使って分析します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": [
    "# Snowpark Pandas API\n",
    "import modin.pandas as spd\n",
    "# Import the Snowpark pandas plugin for modin\n",
    "import snowflake.snowpark.modin.plugin\n",
    "import streamlit as st\n",
    "\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.context import get_active_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "snowpark_session"
   },
   "outputs": [],
   "source": [
    "# Snowflake のアクティブなセッション（現在接続中のセッション）を取得する\n",
    "# これによって、以降の処理で Snowflake に対して SQL 実行やデータ操作ができるようになる\n",
    "session = get_active_session()\n",
    "\n",
    "# セッションに「クエリタグ (query tag)」を設定する\n",
    "# クエリタグとは、Snowflake 上で実行した SQL クエリに「ラベル」を付ける仕組み\n",
    "# これにより、モニタリングやトラブルシューティングで\n",
    "# 「どのアプリから来たクエリか」「どのハンズオン教材からの実行か」などを追跡できる\n",
    "session.query_tag = {\n",
    "    \"origin\": \"sf_devrel\",          # クエリの発行元（ここでは Snowflake Developer Relations の意味）\n",
    "    \"name\": \"de_100_vhol\",          # このハンズオンや演習の名前\n",
    "    \"version\": {                    # バージョン情報\n",
    "        \"major\": 1,\n",
    "        \"minor\": 0\n",
    "    },\n",
    "    \"attributes\": {                 # 追加の属性情報（カスタムラベルのようなもの）\n",
    "        \"is_quickstart\": 1,         # Quickstart チュートリアルからの実行であることを示す\n",
    "        \"source\": \"notebook\",       # Jupyter Notebook や Snowflake Notebook からの実行であることを示す\n",
    "        \"vignette\": \"snowpark_pandas\"  # この教材のシナリオ名（Snowpark + pandas のハンズオンであること）\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109ca7b-e6e2-4fc2-bc33-801e1bebf29f",
   "metadata": {
    "collapsed": false,
    "name": "to_do_1"
   },
   "source": [
    "### TODO: ダウンロードした, 出荷データ(shipping-logs.csv)を Notebooks ワークスペースに読み込む\n",
    "- 画面左側の[➕]ボタンからファイルをアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98d82e-5259-4e73-aabe-79bbb2b59c38",
   "metadata": {
    "language": "python",
    "name": "shipping_logs"
   },
   "outputs": [],
   "source": [
    "# Snowpark pandas（spd）を使って CSV ファイルを読み込む\n",
    "# 'shipping-logs.csv' という名前のCSVファイルを対象にしている\n",
    "# CSVの中に 'shipping_date' という列があり、それを日付型（datetime型）として扱うよう指定している\n",
    "shipping_logs_mdf = spd.read_csv(\n",
    "    'shipping-logs.csv',        # 読み込むCSVファイルの名前\n",
    "    parse_dates=['Shipping Date']  # この列を「文字列」ではなく「日付」として読み込む\n",
    ")\n",
    "\n",
    "# 読み込んだデータ（shipping_logs_mdf）を表示する\n",
    "# shipping_logs_mdf は pandas.DataFrame と同じように扱えるオブジェクト\n",
    "shipping_logs_mdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be0fbae-e6ef-462e-8ddb-e575b59e3b74",
   "metadata": {
    "collapsed": false,
    "name": "to_do_2"
   },
   "source": [
    "### TODO: ダウンロードした, 注文履歴データ(order-history.csv)を Notebooks ワークスペースに読み込む\n",
    "- 画面左側の[➕]ボタンからファイルをアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be293e-956d-4781-be26-bbbdd94afc97",
   "metadata": {
    "language": "python",
    "name": "order_history"
   },
   "outputs": [],
   "source": [
    "# Snowpark pandas（spd）を使って CSV ファイルを読み込む\n",
    "# 'order-history.csv' という名前のCSVファイルを対象にしている\n",
    "# CSVの中に 'Date' という列があり、それを日付型（datetime型）として扱うように指定している\n",
    "order_history_mdf = spd.read_csv(\n",
    "    'order-history.csv',   # 読み込むCSVファイルの名前\n",
    "    parse_dates=['Ordered Date']   # 'Date' 列を文字列ではなく「日付」として扱う\n",
    ")\n",
    "\n",
    "# 読み込んだデータ（order_history_mdf）を表示する\n",
    "# order_history_mdf は pandas.DataFrame と同じように扱えるオブジェクト\n",
    "order_history_mdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87b19c-07ca-4bec-8779-d6396126179b",
   "metadata": {
    "language": "python",
    "name": "rename_columns"
   },
   "outputs": [],
   "source": [
    "# order_history_mdf の列名を分かりやすく変更する\n",
    "# ****(columns={...}) で「元の列名 : 新しい列名」を指定する\n",
    "\n",
    "order_history_mdf = order_history_mdf.rename(columns = {\n",
    "    'Order ID': 'order_id',              # 注文ID → order_id\n",
    "    'Customer ID': 'customer_id',        # 顧客ID → customer_id\n",
    "    'Product ID': 'product_id',          # 商品ID → product_id\n",
    "    'Product Name': 'product_name',      # 商品名 → product_name\n",
    "    'Quantity Ordered': 'quantity_ordered',  # 注文数 → quantity_ordered\n",
    "    'Price': 'price',                    # 単価 → price\n",
    "    'Total Price': 'total_price',        # 合計金額 → total_price\n",
    "    'Ordered Date': 'date'                       # 日付 → date\n",
    "})\n",
    "\n",
    "# 列名が正しく変更されたかを確認する\n",
    "order_history_mdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e9f31f-f328-4b33-b567-fb879efa0f9e",
   "metadata": {
    "collapsed": false,
    "name": "remove_dollar"
   },
   "source": [
    "### 価格カラムから $ 記号を取り除いて整理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b710b6-cee7-478e-9870-c2dd5c3119f8",
   "metadata": {
    "language": "python",
    "name": "clean_price_func"
   },
   "outputs": [],
   "source": [
    "# 文字列で表現された価格（例: \"$19.99\"）を数値に変換する関数\n",
    "def clean_price(price_str):\n",
    "    # 価格の文字列から \"$\" 記号を取り除き、前後の余分な空白も削除する\n",
    "    # 例: \" $19.99 \" → \"19.99\"\n",
    "    cleaned = price_str.replace('$', '').strip()\n",
    "    \n",
    "    # 文字列になっている数値を float型（小数点を持つ数値）に変換する\n",
    "    # 例: \"19.99\" → 19.99\n",
    "    return float(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2da873-f6ed-4e62-9518-845dc99e5ac9",
   "metadata": {
    "language": "python",
    "name": "clean_up_price_values"
   },
   "outputs": [],
   "source": [
    "# ---- 価格カラムを数値に変換する処理 ----\n",
    "\n",
    "# 'price' 列に対して clean_price 関数を適用する\n",
    "# これにより \"$19.99\" のような文字列が 19.99 という float型の数値になる\n",
    "order_history_mdf['price'] = order_history_mdf['price'].apply(clean_price)\n",
    "\n",
    "# 'total_price' 列に対しても同じく clean_price を適用する\n",
    "# これで合計金額も数値として扱えるようになる\n",
    "order_history_mdf['total_price'] = order_history_mdf['total_price'].apply(clean_price)\n",
    "\n",
    "\n",
    "# ---- 変換後のデータ型を確認する処理 ----\n",
    "\n",
    "# price 列のデータ型を表示（float になっていればOK）\n",
    "print(\"\\nPrice column data type:\", order_history_mdf['price'].dtype)\n",
    "\n",
    "# total_price 列のデータ型を表示（こちらも float になっていればOK）\n",
    "print(\"Total price column data type:\", order_history_mdf['total_price'].dtype)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae513f-b06b-4a08-9bf5-e97db9a98eed",
   "metadata": {
    "language": "python",
    "name": "check_clean_up_price_values"
   },
   "outputs": [],
   "source": [
    "# 実際に $ が消えて数値化されているかを表で確認\n",
    "order_history_mdf.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d9aaed-ab1c-482f-b87e-fa4c3955fdac",
   "metadata": {
    "collapsed": false,
    "name": "join_order_shipping"
   },
   "source": [
    "### 製品ごとの注文数を計算する：order_history と shipping_logs を結合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312cfffd-e1fc-4fdb-bc42-dcfb99eb1bdd",
   "metadata": {
    "language": "python",
    "name": "rename_columns2"
   },
   "outputs": [],
   "source": [
    "# order_history_mdf の列名を分かりやすく変更する\n",
    "# ****(columns={...}) で「元の列名 : 新しい列名」を指定する\n",
    "\n",
    "shipping_logs_mdf = shipping_logs_mdf.rename(columns = {\n",
    "    'Order ID': 'order_id',              # 注文ID → order_id\n",
    "    'Shipping Date': 'shipping_date',    # 発送日 → shipping_date\n",
    "    'Carrier': 'carrier',                # 配送業者 → carrier\n",
    "    'Tracking Number': 'trucking_number',# 追跡番号 → trucking_number\n",
    "    'Latitude': 'latitude',              # 緯度 → lattitude\n",
    "    'Longitude': 'longitude',            # 経度 → longitude\n",
    "    'Shipping Status': 'status'         # ステータス → status\n",
    "})\n",
    "\n",
    "# 列名が正しく変更されたかを確認する\n",
    "shipping_logs_mdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8cd02-16c1-4999-8870-da25c1281f27",
   "metadata": {
    "language": "python",
    "name": "join_tables"
   },
   "outputs": [],
   "source": [
    "# ---- 注文データと出荷データを結合 ----\n",
    "\n",
    "# order_history_mdf（注文データ）と shipping_logs_mdf（出荷データ）を\n",
    "# 'order_id' 列をキーにして結合（マージ）する\n",
    "\n",
    "order_shipping_mdf = spd.merge(\n",
    "    order_history_mdf,      # 左側のデータフレーム（注文履歴）\n",
    "    shipping_logs_mdf,      # 右側のデータフレーム（出荷ログ）\n",
    "    on='order_id',          # 結合キーとなる列\n",
    "    how='inner'             # 内部結合（両方に存在するデータのみ）\n",
    ")\n",
    "\n",
    "# 結合後のデータフレームの先頭5行を表示して確認\n",
    "order_shipping_mdf.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb33443-f7c3-41a5-acfe-6cbe634ab990",
   "metadata": {
    "language": "python",
    "name": "product_order_counts"
   },
   "outputs": [],
   "source": [
    "# ---- 商品ごとの注文件数を集計 ----\n",
    "\n",
    "# 'product_name' 列でグループ化して、注文件数を数える\n",
    "# ****() は各グループの行数（＝注文数）をカウントする\n",
    "# reset_index(name='order_count') で結果をデータフレーム形式に戻し、列名を 'order_count' に設定\n",
    "product_counts_mdf = order_shipping_mdf.groupby('product_name').size().reset_index(name='order_count')\n",
    "\n",
    "# ---- 注文件数の多い順に並べ替え ----\n",
    "\n",
    "# sort_values() で 'order_count' 列を降順（ascending=False）に並べる\n",
    "product_counts_mdf = product_counts_mdf.sort_values('order_count', ascending=False)\n",
    "\n",
    "# ---- 結果を表示 ----\n",
    "print(\"\\nProduct Order Counts:\")\n",
    "st.dataframe(product_counts_mdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cd23f-deb0-41b3-91f5-7294a6ee6267",
   "metadata": {
    "collapsed": false,
    "name": "pivot"
   },
   "source": [
    "### 注文の配送ステータスごとにピボットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803b11b-55e1-4b44-869f-e67d3c95639c",
   "metadata": {
    "language": "python",
    "name": "product_status_pivot"
   },
   "outputs": [],
   "source": [
    "# ---- 商品ごとの注文ステータス別集計 ----\n",
    "\n",
    "# **** を使って集計\n",
    "# index='product_name' → 行に商品名を設定\n",
    "# columns='status' → 列に注文ステータス（例: shipped, pending, cancelled）を設定\n",
    "# values='order_id' → 注文IDを数える対象にする\n",
    "# aggfunc='count' → 各セルに注文数をカウント\n",
    "# fill_value=0 → データがない場合は 0 を埋める\n",
    "product_status_pivot_mdf = order_shipping_mdf.pivot_table(\n",
    "    index='product_name',\n",
    "    columns='status',\n",
    "    values='order_id',\n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# ---- 合計注文数の列を追加 ----\n",
    "\n",
    "# 行ごとの合計を計算して 'Total_Orders' 列として追加\n",
    "product_status_pivot_mdf['Total_Orders'] = product_status_pivot_mdf.sum(axis=1)\n",
    "\n",
    "# ---- 合計注文数の多い順に並べ替え ----\n",
    "\n",
    "product_status_pivot_mdf = product_status_pivot_mdf.sort_values('Total_Orders', ascending=False)\n",
    "\n",
    "# ---- 結果を表示 ----\n",
    "print(\"\\nProduct Orders by Status:\")\n",
    "st.dataframe(product_status_pivot_mdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8654c-416d-4279-8c21-b53987491ca8",
   "metadata": {
    "collapsed": false,
    "name": "intro2"
   },
   "source": [
    "## Avalanche社は、各製品に対する顧客レビューについても理解したいと考えています。  \n",
    "\n",
    "\n",
    "この分析を [Snowpark DataFrame API](https://docs.snowflake.com/en/developer-guide/snowpark/python/working-with-dataframes) を使って実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a31fe-3a77-4966-bfef-c29cb3c1fe1a",
   "metadata": {
    "language": "sql",
    "name": "create_snowflake_objects"
   },
   "outputs": [],
   "source": [
    "-- ---- データベースとスキーマの作成（Snowsight UI で実行する場合） ----\n",
    "-- CREATE OR REPLACE DATABASE avalanche_db;\n",
    "-- CREATE OR REPLACE SCHEMA avalanche_schema;\n",
    "\n",
    "-- 既存データベースを使用する\n",
    "USE DATABASE avalanche_db;\n",
    "\n",
    "-- 既存スキーマを使用する\n",
    "USE SCHEMA avalanche_schema;\n",
    "\n",
    "\n",
    "-- ---- ファイルを格納するステージ（Stage）の作成 ----\n",
    "-- Stage とは、Snowflake にデータを取り込む前に一時的にファイルを置いておく場所です\n",
    "CREATE OR REPLACE STAGE avalanche_stage\n",
    "  URL = 's3://sfquickstarts/misc/avalanche/csv/'  -- S3 バケットの場所を指定\n",
    "  DIRECTORY = (ENABLE = TRUE AUTO_REFRESH = TRUE); -- ディレクトリ構造を有効化、自動更新ON\n",
    "\n",
    "-- Stage 内のファイル一覧を確認\n",
    "ls @avalanche_stage;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f6a184-8c2f-4d54-a606-fd3f2acc1d22",
   "metadata": {
    "collapsed": false,
    "name": "load_reviews"
   },
   "source": [
    "### 顧客レビューを Snowflake のテーブルに読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903c319-f55a-4773-8e58-daaec82f72d3",
   "metadata": {
    "language": "sql",
    "name": "create_customer_reviews_table"
   },
   "outputs": [],
   "source": [
    "-- ---- テーブルの作成 ----\n",
    "-- customer_reviews という名前のテーブルを作成\n",
    "-- 商品名、レビュー日、レビュー本文、感情スコアを保存する\n",
    "CREATE OR REPLACE TABLE customer_reviews (\n",
    "    product VARCHAR,          -- 商品名（文字列）\n",
    "    date DATE,                -- レビュー日（DATE型）\n",
    "    summary TEXT,             -- レビュー本文（TEXT型）\n",
    "    sentiment_score FLOAT     -- 感情スコア（数値、小数点）\n",
    ");\n",
    "\n",
    "\n",
    "-- ---- CSV ファイルからデータをテーブルにロード ----\n",
    "COPY INTO customer_reviews\n",
    "FROM @avalanche_stage/customer_reviews.csv   -- 先ほど作成した Stage 内の CSV を指定\n",
    "FILE_FORMAT = (\n",
    "    TYPE = CSV,                               -- CSV形式のファイル\n",
    "    FIELD_DELIMITER = ',',                     -- カラム区切り文字はカンマ\n",
    "    SKIP_HEADER = 1,                           -- 1行目はヘッダーなのでスキップ\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"',       -- 値が \" \" で囲まれている場合に対応\n",
    "    TRIM_SPACE = TRUE,                         -- 前後の空白を削除\n",
    "    NULL_IF = ('NULL', 'null'),               -- \"NULL\" または \"null\" は NULL として扱う\n",
    "    EMPTY_FIELD_AS_NULL = TRUE                -- 空欄も NULL として扱う\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558d8e0-c499-4ae5-9ca0-85497fedc71a",
   "metadata": {
    "language": "python",
    "name": "load_customer_reviews"
   },
   "outputs": [],
   "source": [
    "# ---- Snowflake テーブルを Snowpark DataFrame として読み込む ----\n",
    "\n",
    "# 'customer_reviews' テーブルを Snowpark DataFrame として取得\n",
    "customer_reviews_sdf = session.table('customer_reviews')\n",
    "\n",
    "# 取得した Snowpark DataFrame の内容を確認\n",
    "customer_reviews_sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eddc5a-cd65-4ceb-a20e-057eade19152",
   "metadata": {
    "language": "python",
    "name": "average_sentiment_scores"
   },
   "outputs": [],
   "source": [
    "# ---- Product単位でSENTIMENT_SCOREの平均を集計する ----\n",
    "product_sentiment_sdf = customer_reviews_sdf.group_by('PRODUCT') \\\n",
    "    .agg(F.round(F.avg('SENTIMENT_SCORE'),2).alias('AVG_SENTIMENT_SCORE')) \\\n",
    "    .sort(F.col('AVG_SENTIMENT_SCORE').desc())\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nAverage Sentiment Scores by Product:\")\n",
    "product_sentiment_sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125cda9-34ed-421b-ab71-b92b5ba546a4",
   "metadata": {
    "collapsed": false,
    "name": "visualize_md"
   },
   "source": [
    "## 📊 データの可視化\n",
    "\n",
    "[Altair](https://altair-viz.github.io/)を使用して、データ分布をヒストグラムとして簡単に可視化できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01df47-4480-4069-adca-954fb3bb8fc0",
   "metadata": {
    "language": "python",
    "name": "visualize"
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# 追加したパッケージ\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf = customer_reviews_sdf.to_pandas()\n",
    "chart = alt.Chart(pdf, title='評価分布').mark_bar().encode(\n",
    "    alt.X(\"SENTIMENT_SCORE\", bin=alt.Bin(step=0.5)),\n",
    "    y='count()'\n",
    ")\n",
    "\n",
    "st.altair_chart(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987baa63-1214-40f2-b323-fdf963c63876",
   "metadata": {
    "collapsed": false,
    "name": "plotting_md"
   },
   "source": [
    "チャートをカスタマイズして、カーネル密度推定（KDE）と中央値をプロットしたいとします。matplotlibを使用して価格分布をプロットできます。`.plot`コマンドは内部的に`scipy`を使用してKDEプロファイルを計算することに注意してください。これは、このチュートリアルの前半でパッケージとして追加したものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6993a-e1eb-49b1-bfab-f32cc9350eb9",
   "metadata": {
    "language": "python",
    "name": "plotting"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,3))\n",
    "plt.tick_params(left = False, right = False , labelleft = False) \n",
    "\n",
    "price = order_history_mdf[\"price\"]\n",
    "price.plot(kind = \"hist\", density = True, bins = 15)\n",
    "price.plot(kind=\"kde\", color='#c44e52')\n",
    "\n",
    "\n",
    "# パーセンタイルを計算\n",
    "median = price.median()\n",
    "ax.axvline(median,0, color='#dd8452', ls='--')\n",
    "ax.text(median,0.8, f'Median: {median:.2f}  ',\n",
    "        ha='right', va='center', color='#dd8452', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# チャートを美しくする\n",
    "plt.style.use(\"bmh\")\n",
    "plt.title(\"Price Distribution\")\n",
    "plt.xlabel(\"Price (Binned)\")\n",
    "left, right = plt.xlim()   \n",
    "plt.xlim((0, right))  \n",
    "# 目盛りと軸線を削除\n",
    "ax.tick_params(left = False, bottom = False)\n",
    "for ax, spine in ax.spines.items():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa1fbd-5483-4e60-a893-f92fab942ad6",
   "metadata": {
    "collapsed": false,
    "name": "cell_reference_md"
   },
   "source": [
    "## サブクエリ/セル間の参照\n",
    "\n",
    "セルに名前をつけて、後続のセルでその出力を参照することができます\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8bf3e-25a1-458d-8f59-169f4a1ec220",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "Jinjaを利用して別のSQLセルからSQLテーブルを参照することで、CTEを簡素化することができます。\n",
    "\n",
    "```sql\n",
    "SELECT * FROM {{cell}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15afa98b-8abf-4888-9029-cf197cc05393",
   "metadata": {
    "language": "sql",
    "name": "subqueries"
   },
   "outputs": [],
   "source": [
    "select \n",
    "    product, \n",
    "    avg(sentiment_score) as avg_score, \n",
    "    min(sentiment_score) as min_score, \n",
    "    max(sentiment_score) as max_score\n",
    "from customer_reviews\n",
    "group by all;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d7660-8ecc-4b3e-89e3-619907a8d966",
   "metadata": {
    "language": "sql",
    "name": "subqueries2"
   },
   "outputs": [],
   "source": [
    "select * from {{subqueries}}\n",
    "WHERE avg_score > 0.5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fde296-4fa7-49bf-add4-79cafe529d48",
   "metadata": {
    "collapsed": false,
    "name": "cell4"
   },
   "source": [
    "SQL結果にPythonから直接アクセスし、結果をpandas DataFrameに変換できます。🐼\n",
    "\n",
    "```python\n",
    "# SQLセルの出力をSnowpark DataFrameとしてアクセス\n",
    "my_snowpark_df = sql_querying.to_df()\n",
    "``` \n",
    "\n",
    "```python\n",
    "# SQLセルの出力をpandas DataFrameに変換\n",
    "my_df = sql_querying.to_pandas()\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4677009-d9e0-4690-82ab-8a7196026fae",
   "metadata": {
    "language": "python",
    "name": "cell_reference"
   },
   "outputs": [],
   "source": [
    "my_df = subqueries2.to_df()\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58c54d-15fa-4fba-a124-1a56a7947b29",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "## ステージパッケージの追加\n",
    "使用したいPythonパッケージがAnacondaで利用できない場合は、パッケージをステージにアップロードし、ステージからインポートすることができます。ここでは、カスタムパッケージをノートブックにインポートする簡単な例を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e372-2354-48c9-8a27-f388ab75ffef",
   "metadata": {
    "language": "sql",
    "name": "git_integration"
   },
   "outputs": [],
   "source": [
    "-- ステージの作成\n",
    "CREATE OR REPLACE STAGE AVALANCHE_DB.AVALANCHE_SCHEMA.FILE DIRECTORY = (ENABLE = TRUE);\n",
    "\n",
    "// Step3: 公開されているGitからスクリプトを取得 //\n",
    "-- Git連携のため、API統合を作成する\n",
    "CREATE OR REPLACE API INTEGRATION git_api_integration\n",
    "  API_PROVIDER = git_https_api\n",
    "  API_ALLOWED_PREFIXES = ('https://github.com/sfc-gh-skawakami/')\n",
    "  ENABLED = TRUE;\n",
    "\n",
    "-- GIT統合の作成\n",
    "CREATE OR REPLACE GIT REPOSITORY GIT_INTEGRATION_FOR_HANDSON\n",
    "  API_INTEGRATION = git_api_integration\n",
    "  ORIGIN = 'https://github.com/sfc-gh-skawakami/sfc-jp-notebook_de_101.git';\n",
    "\n",
    "\n",
    "ALTER GIT REPOSITORY GIT_INTEGRATION_FOR_HANDSON FETCH;\n",
    "\n",
    "-- チェックする\n",
    "ls @GIT_INTEGRATION_FOR_HANDSON/branches/main;\n",
    "\n",
    "-- Githubからファイルを持ってくる\n",
    "COPY FILES INTO @AVALANCHE_DB.AVALANCHE_SCHEMA.FILE FROM @GIT_INTEGRATION_FOR_HANDSON/branches/main/simple.zip;\n",
    "ls @AVALANCHE_DB.AVALANCHE_SCHEMA.FILE;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89368f4-1053-481b-a446-d4e1874b8f83",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "`simple.zip`の内容\n",
    "\n",
    "simple/__init__.py\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "\n",
    "def greeting():\n",
    "  return \"Hello world!\"\n",
    "\n",
    "def hi():\n",
    "  st.write(greeting())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c601241-1133-4280-9486-9527a480629b",
   "metadata": {
    "language": "python",
    "name": "stage_packages"
   },
   "outputs": [],
   "source": [
    "import simple\n",
    "\n",
    "simple.hi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c4e657-880f-4f55-bab6-5a7ea4690c04",
   "metadata": {
    "collapsed": false,
    "name": "private_repo"
   },
   "source": [
    "## プライベートリポジトリからのインポート\n",
    "```\n",
    "コンテナランタイムでのみ使用可能\n",
    "```\n",
    "Pipは、JFrog Artifactoryのようなプライベートソースからのパッケージのインストールを基本認証でサポートしています。ノートブックを外部アクセス統合（External Access Integration）用に設定し、リポジトリにアクセスできるようにします。\n",
    "\n",
    "1. ネットワークルールを作成し、アクセスしたいリポジトリを指定します。例えば、このネットワークルールはJFrogリポジトリを指定しています:\n",
    "```sql\n",
    "CREATE OR REPLACE NETWORK RULE jfrog_network_rule\n",
    "  MODE = EGRESS\n",
    "  TYPE = HOST_PORT\n",
    "  VALUE_LIST = ('<your-repo>.jfrog.io');\n",
    "```\n",
    "2. 外部ネットワーク位置への認証に必要な資格情報を表すシークレットを作成します。\n",
    "```sql\n",
    "CREATE OR REPLACE SECRET jfrog_token\n",
    "  TYPE = GENERIC_STRING\n",
    "  SECRET_STRING = '<your-jfrog-token>';\n",
    "```\n",
    "3. リポジトリへのアクセスを許可する外部アクセス統合を作成します：\n",
    "```sql\n",
    "CREATE OR REPLACE EXTERNAL ACCESS INTEGRATION jfrog_integration\n",
    "  ALLOWED_NETWORK_RULES = (jfrog_network_rule)\n",
    "  ALLOWED_AUTHENTICATION_SECRETS = (jfrog_token)\n",
    "  ENABLED = TRUE;\n",
    "\n",
    "GRANT USAGE ON INTEGRATION jfrog_integration TO ROLE data_scientist;\n",
    "```\n",
    "4. 外部アクセス統合とシークレットをノートブックに関連付けます。\n",
    "```sql\n",
    "ALTER NOTEBOOK my_notebook\n",
    "  SET EXTERNAL_ACCESS_INTEGRATIONS = (jfrog_integration),\n",
    "    SECRETS = ('jfrog_token' = jfrog_token);\n",
    "```\n",
    "5. 外部アクセス設定にアクセスするには、ノートブックの右上にある「ワークシートのその他のアクション」（ノートブックアクションメニュー）を選択します。\n",
    "6. 「ノートブック設定」を選択し、次に「External Access」タブを選択します。\n",
    "7. リポジトリに接続する外部アクセス統合を選択します。\n",
    "ノートブックが再起動します。\n",
    "8. ノートブックが再起動されたら、リポジトリからインストール可能になります\n",
    "```cmd\n",
    "!pip install hello-jfrog --index-url https://<user>:<token>@<your-repo>.jfrog.io/artifactory/api/pypi/test-pypi/simple\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a09b1f-b725-486a-af35-7da9266745b7",
   "metadata": {
    "collapsed": false,
    "name": "working_with_file_md"
   },
   "source": [
    "# Snowflake Notebooksでファイルを扱う方法 🗄️\n",
    "\n",
    "この例では、notebooksでファイルを扱う方法と、それらをstageに永続的に保存する方法を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cf8487-e6a5-4152-8cbe-f1df81644d61",
   "metadata": {
    "collapsed": false,
    "name": "temp_file_md"
   },
   "source": [
    "## 一時ファイルの操作\n",
    "\n",
    "notebookから書き込んだファイルは、notebookに関連付けられたlocal stageに一時的に保存されます。\n",
    "\n",
    "**notebookセッションを終了するとすぐに、これらのファイルにアクセスできなくなることに注意してください。**\n",
    "\n",
    "簡単なファイルを作成して、この仕組みの例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced9492-361d-49f2-8845-0a1db3af376f",
   "metadata": {
    "language": "python",
    "name": "temp_file_py1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"myfolder/\")\n",
    "os.chdir(\"myfolder/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72530e0d-76c8-4dd8-9b2a-7d9525aeda1d",
   "metadata": {
    "language": "python",
    "name": "temp_file_py2"
   },
   "outputs": [],
   "source": [
    "with open(\"myfile.txt\",'w') as f:\n",
    "    f.write(\"abc\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b3896-0ea9-4f2e-93db-55b3ccc7ec43",
   "metadata": {
    "collapsed": false,
    "name": "temp_file_md2"
   },
   "source": [
    "stageにあるファイルを確認してみましょう。`notebook_app.ipynb`と`environment.yml`はSnowflake notebookの一部として自動的に作成されるファイルです。新しく作成したファイル`myfile.txt`が確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b33e1-f213-41e2-8444-aaf1fb089926",
   "metadata": {
    "language": "python",
    "name": "temp_file_py3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468563f5-3ff4-4f7b-8c2e-d9be299ea5d7",
   "metadata": {
    "collapsed": false,
    "name": "temp_file_md3"
   },
   "source": [
    "では、notebookをセッションから切断してみましょう。これは、ブラウザページを閉じる/更新するか、右上の`Active`ボタンをクリックして`End session`を押すことで行えます。\n",
    "\n",
    "このセルから開始してnotebookを再実行すると、前回のnotebookセッション中に作成したファイル`myfile.txt`は失われます。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5f12d-48a1-4442-b1c3-3dcd031a3244",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b6b56-cbc8-4d7f-a427-5f211d0ff4b1",
   "metadata": {
    "collapsed": false,
    "name": "cell6"
   },
   "source": [
    "## 永続ファイルの操作\n",
    "\n",
    "セッションに戻ったときに再度アクセスできる永続的な場所にファイルを保存したい場合はどうでしょうか？例えば、モデルを訓練して後で使用するためにモデルを保存したい場合や、分析結果を保存したい場合があります。notebookセッション中に作成されたファイルはデフォルトで一時的なものなので、永続的なSnowflake stageにファイルを移動してファイルを永続的に保存する方法を説明します。\n",
    "\n",
    "まず、`PERMANENT_STAGE`という名前のstageを作成しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30758b36-6c49-461f-9c80-a11c71b33f11",
   "metadata": {
    "language": "sql",
    "name": "save_file_sql1"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE STAGE PERMANENT_STAGE;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec38b2b-1c57-4d57-818b-bc1d995961c4",
   "metadata": {
    "collapsed": false,
    "name": "save_file_md2"
   },
   "source": [
    "では、再び一時的なlocal stageに`myfile.txt`を書き込みましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7964b-6ebd-4571-8aa0-4b4856925848",
   "metadata": {
    "language": "python",
    "name": "save_file_py1"
   },
   "outputs": [],
   "source": [
    "with open(\"myfile.txt\",'w') as f:\n",
    "    f.write(\"abc\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022652cf-678b-4550-af00-84fce30ece46",
   "metadata": {
    "collapsed": false,
    "name": "save_file_md3"
   },
   "source": [
    "では、Snowparkを使用して作成したローカルファイルをstageの場所にアップロードしましょう。Notebooksでは、`get_active_session`メソッドを使用して[session](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.Session#snowflake.snowpark.Session)コンテキスト変数を取得し、以下のようにSnowparkを操作できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e7c78-8e9b-4d9a-9579-bba94b552b42",
   "metadata": {
    "language": "python",
    "name": "save_file_py2"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc22eea0-8b8a-490a-b63c-ce606c126a9e",
   "metadata": {
    "collapsed": false,
    "name": "save_file_md4"
   },
   "source": [
    "Snowparkの[session.file.put](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.FileOperation.put)コマンドを使用して、`myfile.txt`をstageの場所`@PERMANENT_STAGE`に移動しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc449230-e744-4b61-a6f7-4d425abd48ac",
   "metadata": {
    "language": "python",
    "name": "save_file_py3"
   },
   "outputs": [],
   "source": [
    "put_result = session.file.put(\"myfile.txt\",\"@PERMANENT_STAGE\", auto_compress= False)\n",
    "put_result[0].status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa4190-91a9-4f56-9f46-9e2b4ef0f7c9",
   "metadata": {
    "collapsed": false,
    "name": "save_file_md5"
   },
   "source": [
    "ファイルが永続stageにアップロードされました。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50cf40-b7b0-4ecd-918b-bb0a98bff7a7",
   "metadata": {
    "language": "sql",
    "name": "save_file_sql3"
   },
   "outputs": [],
   "source": [
    "LS @PERMANENT_STAGE;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d2da4-91d7-4b68-811a-9292d4749562",
   "metadata": {
    "collapsed": false,
    "name": "save_file_md6"
   },
   "source": [
    "notebookセッションを切断しても、ファイルが永続stageに残存していることが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f44c59d-6dc1-416c-81c3-74e69842299b",
   "metadata": {
    "language": "sql",
    "name": "save_file_sql4"
   },
   "outputs": [],
   "source": [
    "LS @PERMANENT_STAGE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a31c6d-2389-446e-95ef-a170ba4fff70",
   "metadata": {
    "language": "python",
    "name": "save_file_py4"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "f = session.file.get_stream(\"@PERMANENT_STAGE/myfile.txt\")\n",
    "print(f.readline())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee499b-485d-41e6-97aa-58aab3c3c986",
   "metadata": {
    "collapsed": false,
    "name": "save_file_md7"
   },
   "source": [
    "また、読み取る前にファイルをローカルにダウンロードしたい場合は、[session.file.get](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.FileOperation.get)コマンドを使用できます： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d7788-c220-482d-b531-54dbfe899757",
   "metadata": {
    "language": "python",
    "name": "save_file_py5"
   },
   "outputs": [],
   "source": [
    "# Download the file from stage to current local path\n",
    "get_status = session.file.get(\"@PERMANENT_STAGE/myfile.txt\",\"./\")\n",
    "get_status[0].status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5475f1b-c2b4-47fa-9a5c-3ebc3197ca59",
   "metadata": {
    "language": "python",
    "name": "save_file_py6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cdf837-3a01-4b7b-8e75-ede94db78ae7",
   "metadata": {
    "collapsed": false,
    "name": "save_stage_md1"
   },
   "source": [
    "## ボーナス: stageからのデータファイルの操作\n",
    "\n",
    "stageは、Snowflakeに読み込まれる前にデータファイルを保存する一般的な場所です。前のセクションでは、Snowflake stageに汎用ファイルを読み書きする方法を見ました。ここでは、stageに保存されたテーブル形式のデータファイルを操作する一般的な例をいくつか紹介します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a91911-89b0-414a-a020-a0a959f0deba",
   "metadata": {
    "language": "python",
    "name": "save_stage_py1"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6180d-8953-428d-81e5-8bbf001be330",
   "metadata": {
    "collapsed": false,
    "name": "save_stage_md2"
   },
   "source": [
    "異なる日における様々なスキーリゾート地での降雪量を記録したサンプルデータセットがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6435fa-f390-4757-8584-42862524207c",
   "metadata": {
    "language": "python",
    "name": "save_stage_py2"
   },
   "outputs": [],
   "source": [
    "# Create a Snowpark DataFrame with sample data\n",
    "df = session.create_dataframe([[1, 'Big Bear', 8],[2, 'Big Bear', 10],[3, 'Big Bear', 5],\n",
    "                               [1, 'Tahoe', 3],[2, 'Tahoe', 20],[3, 'Tahoe', 13]], \n",
    "                              schema=[\"DAY\", \"LOCATION\", \"SNOWFALL\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d2f34-1fac-4947-a407-4be4b666be5d",
   "metadata": {
    "collapsed": false,
    "name": "save_stage_md3"
   },
   "source": [
    "Snowpark dataframeをstage上のCSVファイルに書き込む方法は次の通りです："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569357c0-beeb-400e-ba98-2628b04dea5f",
   "metadata": {
    "language": "python",
    "name": "save_stage_py3"
   },
   "outputs": [],
   "source": [
    "df.write.copy_into_location(\"@PERMANENT_STAGE/snowfall.csv\",file_format_type=\"csv\",header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9727e8f-7b0f-4118-a738-ffbfd47b2dc0",
   "metadata": {
    "collapsed": false,
    "name": "save_stage_md4"
   },
   "source": [
    "stage上のファイルにアクセスするには、stageの場所からCSVファイルを読み取ってSnowpark dataframeに戻します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1961184-98fe-4efa-aee5-07c26fb6675b",
   "metadata": {
    "language": "python",
    "name": "save_stage_py4"
   },
   "outputs": [],
   "source": [
    "df = session.read.options({\"infer_schema\":True}).csv('@PERMANENT_STAGE/snowfall.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfe10c-7a31-41d1-8880-288efac3b6dc",
   "metadata": {
    "collapsed": false,
    "name": "save_stage_md5"
   },
   "source": [
    "notebooksでデータファイルを操作する方法について詳しく学ぶには、[外部S3 stageからCSVファイルを操作する方法](https://github.com/Snowflake-Labs/snowflake-demo-notebooks/blob/main/Load%20CSV%20from%20S3/Load%20CSV%20from%20S3.ipynb)と[パブリックエンドポイントからSnowflakeテーブルにデータを読み込む方法](https://github.com/Snowflake-Labs/snowflake-demo-notebooks/blob/main/Ingest%20Public%20JSON/Ingest%20Public%20JSON.ipynb)のチュートリアルをご確認ください。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3db0d-8ab9-4a90-96e2-5f3ec1874adf",
   "metadata": {
    "language": "sql",
    "name": "save_stage_sql1"
   },
   "outputs": [],
   "source": [
    "-- Teardown stage created as part of this tutorial\n",
    "DROP STAGE PERMANENT_STAGE;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "shinichi.kawakami@snowflake.com",
   "authorId": "3340353333597",
   "authorName": "SKAWAKAMI",
   "lastEditTime": 1756170420445,
   "notebookId": "t2tu5p7ese4jvc6tfj25",
   "sessionId": "e2f054d9-4805-49ab-a076-5a9ec555fb1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
